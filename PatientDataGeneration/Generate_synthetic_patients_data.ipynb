{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b762d1-dca3-4a69-901c-e20e985d930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install happytransformer\n",
    "# !pip install xformers\n",
    "# !pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8aa3c-c66f-4c0f-ab95-fb31f6d3237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current memory of GPU first: nvtop\n",
    "# Then go to the gpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5499f91e-b9eb-4775-8c19-168a629ce090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ghdevhome/home/cpan/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "004608ca-c2f2-47cf-bda9-9577db33a728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_billing_pdfs.txt\n",
      "breast_cancer_files.txt\n",
      "breast_cancer_matching_files.pkl\n",
      "breast_cancer_processed_file_paths.txt\n",
      "copy_medical_files.ipynb\n",
      "data_vectorized_hierarchical.pkl\n",
      "en_core_web_sm-3.6.0.tar.gz\n",
      "Evaluate_OCR_quality.ipynb\n",
      "experiment_script.py\n",
      "Generate_synthetic_patients_data.ipynb\n",
      "hierarchical_clustering_hyperparameter_tuning.ipynb\n",
      "hierarchical_clustering.ipynb\n",
      "hrd_folders_with_frequency_above_one.pkl\n",
      "\u001b[0m\u001b[01;34mlog_files\u001b[0m/\n",
      "\u001b[01;34mmaxent_ne_chunker\u001b[0m/\n",
      "maxent_ne_chunker.zip\n",
      "\u001b[01;34mmodels\u001b[0m/\n",
      "mychoice_folders_with_frequency_above_one.pkl\n",
      "mychoice_results.csv\n",
      "\u001b[01;32mocr_job.sh\u001b[0m*\n",
      "OCRopus_script.ipynb\n",
      "OCRopus_script.py\n",
      "OCRopus_text_extraction.ipynb\n",
      "\u001b[01;34mpunkt\u001b[0m/\n",
      "punkt.zip\n",
      "test_results_extraction.ipynb\n",
      "text_cleaning_and_deidentification.ipynb\n",
      "vectorizer_hiearchical.pkl\n",
      "\u001b[01;34mwords\u001b[0m/\n",
      "words.zip\n"
     ]
    }
   ],
   "source": [
    "ls '/ghdevhome/home/cpan/notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90c40ee-ab6a-40a5-9387-af609e0d484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3282540-3b2f-41ac-b881-f17738b65c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/ghdevhome/home/cpan/data/'\n",
    "predictions_df = pd.read_csv(data_dir + 'train_docs_sm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fc24098-b15b-4872-9866-7e167b0cf5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>page_content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0569166_MedRec1/image-026.txt</td>\n",
       "      <td>A0569166</td>\n",
       "      <td>2022 11 29 11 11 53 29 47 REDACTED REDACTED My...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0273290_MedRec2/image-033.txt</td>\n",
       "      <td>A0273290</td>\n",
       "      <td>01 05 2022 3 51 51 PM PAGE 37 OF 45 REDACTED R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A83264/image-014.txt</td>\n",
       "      <td>A83264</td>\n",
       "      <td>O1 26 718 11 12 FROM CBSN Tenaya 7027493 708 T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0588576_MedRec1/image-082.txt</td>\n",
       "      <td>A0588576</td>\n",
       "      <td>To 18772418203 Paae 085 of 108 2022 12 01 18 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0340486/image-005.txt</td>\n",
       "      <td>A0340486</td>\n",
       "      <td>To 16173942606 Page 04 of 12 2021 03 31 00 38 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file_name patient_id  \\\n",
       "0  A0569166_MedRec1/image-026.txt   A0569166   \n",
       "1  A0273290_MedRec2/image-033.txt   A0273290   \n",
       "2            A83264/image-014.txt     A83264   \n",
       "3  A0588576_MedRec1/image-082.txt   A0588576   \n",
       "4          A0340486/image-005.txt   A0340486   \n",
       "\n",
       "                                        page_content  label  \n",
       "0  2022 11 29 11 11 53 29 47 REDACTED REDACTED My...      1  \n",
       "1  01 05 2022 3 51 51 PM PAGE 37 OF 45 REDACTED R...      0  \n",
       "2  O1 26 718 11 12 FROM CBSN Tenaya 7027493 708 T...      0  \n",
       "3  To 18772418203 Paae 085 of 108 2022 12 01 18 3...      1  \n",
       "4  To 16173942606 Page 04 of 12 2021 03 31 00 38 ...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dead0cb6-6f95-4ab7-93f6-f215efdef0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(data_dir + 'test_docs_sm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a22a3192-cc7e-43b8-9176-3dd3a1e92570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 4)\n"
     ]
    }
   ],
   "source": [
    "filtered_data = predictions_df[predictions_df['label'] == 1]\n",
    "print(filtered_data.shape)\n",
    "useful_pages = filtered_data['page_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26c8bf3a-d3c8-4e67-b1af-4beea535eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract test result pages from test data \n",
    "test_data = test_df[test_df['label'] ==1]\n",
    "test_pages = test_data['page_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79134189-6fe5-43d6-9d29-dd338168ca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch  # Import PyTorch for GPU support\n",
    "from happytransformer import HappyGeneration, GENSettings\n",
    "import pandas as pd\n",
    "\n",
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b72676-e1d0-41d8-90d5-a42ec03fb8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd84ea3864b42d7a58b03e8ddc3e905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f99b371965b424da1dbec7d1a0d6bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164f29a960b344c5b91412d724c6fb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/560 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7894cfbfa82d4b38b24569d99d75acd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84164d4e88814ceaa448e5926ab788d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78839861392479d9096007d2b204a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/27/2023 13:20:19 - INFO - happytransformer.happy_transformer -   Using device: cuda:0\n",
      "Using pad_token, but it is not set yet.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 50257. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_gen = HappyGeneration(\"GPT-NEO\", \"EleutherAI/gpt-neo-125M\")\n",
    "happy_gen.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "051f97e2-e544-42ff-859b-00b45b2b9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt_template = \"Based on this medical page content,for example: '{}'. \\n Generate a similar synthetic patients' medical page content:\"\n",
    "# Prepare data for different cancer types\n",
    "all_prompts = []\n",
    "# try 10 examples\n",
    "for page_content in useful_pages[:10]:\n",
    "  full_prompt = new_prompt_template.format(page_content)\n",
    "  all_prompts.append(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1875475a-2eb9-4e42-bf4b-f76679805cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on this medical page content,for example: '2022 11 29 11 11 53 29 47 REDACTED REDACTED MyRisk Genetic Result Name REDACTED REDACTED DOBESep 13 1983 Accession 04370339 BLD Report Date Sep 09 2022 BREAST CANCER RISKSCORE REDACTED The breast cancer RiskScore provides 5 year and remaining lifetime breast cancer risks based on an analysis of genetic markers combined with patient clinical and family history data The Technical Specifications summary http myriad com technical specifications describes the RiskScore eligibility criteria analysis method performance and interpretive criteria of this test Data from 149 biomarkers are analyzed during next generation sequencing NGS The allele status of these markers has been weighted to generate a polygenic odds ratio of 1 0 for this patient which is combined with clinical and family history information to generate the final RiskScore This odds ratio is adjusted for overlap between the risk captured by the biomarkers and the clinical factors and has not been validated for use with other risk models The Clinical and Cancer Family History Information section of this report displays the data used for this analysis and explains important limitations on the accuracy of RiskScore including significant over or under estimates of breast cancer risk that can be caused by errors and or omissions in the reported clinical and family history data Please contact REDACTED Medical Services at 1 800 469 7423 K 3850 to discuss any questions regarding this result estilt Page 4 of 4 REDACTED genetics'. \\n Generate a similar synthetic patients' medical page content:\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec7148ea-80bc-4e2a-a3ca-8d3f6c9cf32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepara test prompts \n",
    "all_test_prompts = []\n",
    "# try 10 examples\n",
    "for page_content in test_pages:\n",
    "  full_prompt = new_prompt_template.format(page_content)\n",
    "  all_test_prompts.append(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2ca468b-83aa-48a7-b940-7e45275a0fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/27/2023 13:33:46 - INFO - happytransformer.happy_transformer -   Moving model to cuda:0\n",
      "08/27/2023 13:33:46 - INFO - happytransformer.happy_transformer -   Initializing a pipeline\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " '2022 11 29 11 53 29 47 REDACTED REDACTED MyRisk Genetic Result Name REDACTED REDACTED DOBESep 13 1983 Accession 04370339 BLD Report Date Sep 09 2022 BREAST CANCER RISKSC\n"
     ]
    }
   ],
   "source": [
    "# try an example\n",
    "example_prompt = all_prompts[0]\n",
    "example_res = happy_gen.generate_text(example_prompt)\n",
    "print(example_res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bd4b7-6b57-414d-ac59-de5d756eae3f",
   "metadata": {},
   "source": [
    "### Improve Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4880de79-e33f-4508-abd8-50b761586668",
   "metadata": {},
   "outputs": [],
   "source": [
    "args1 = GENSettings(no_repeat_ngram_size=2,temperature=0.7, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "caefd6aa-1044-482e-9cab-6f22941f7765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " http://www.cis.nhs.uk/mw/data_pages/genetics/risk/RISK_scores.html The Genetic Risk Score is a score for the ability of a person to predict a disease\n"
     ]
    }
   ],
   "source": [
    "example_res1 = happy_gen.generate_text(example_prompt, args=args1)\n",
    "print(example_res1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd32011a-4c90-4102-a3ff-e8843b271ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cpan/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/cpan/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/home/cpan/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " http://www.genetics.org/content/show.php/genetic-genomics-2.html The Genetic Risk Score (GRSS) is a measure of the probability of a patient being a genetic risk factor for a disease. The GRSS is based upon the proportion of patients with a given risk score that are at a higher risk than the patient's risk. This measure is used to determine the likelihood of an individual being at an increased risk of developing a specific disease or condition. GRS is also used in a number of other studies to assess the impact of genetics on health care. For example, the GRAS score is an indicator of how much genetic variation is present in an individuals' genetic profile.\n",
      "\n",
      "The Risk score for the following genes is calculated by dividing the number (or number) of genes in each gene by its number in all genes. A gene is considered to be a risk if its risk scores are greater than or equal to the sum of its scores for all of those genes, or its score equals the total number. If the score of all the genes exceeds the maximum score, then the gene has a greater risk for developing the disease than if the scores of only those of that gene are equal. In this case, a gene may be considered a \"risk factor\" if it is more than a score greater or less than its maximum. Risk factors are defined as follows:\n",
      "1. Genetic Risk: A risk is defined by a set of risk factors that is greater in number than all other genes and is less in risk when compared to all others. Genes are considered as risk in this definition if their risk Scores are less or greater. 2. Gene Risk 1: The gene that has the highest risk, is the one that most closely resembles the genetic variant of interest. 3. gene Risk 2: If a particular gene falls within the set, it falls in that set. 4. risk Score 1. 1 Risk Factor 1 is: 1 risk = 1 gene. 5. genetic Risk 3: Genetic risk 3 is 1 genetic. 6. score 1 score 2 is 0. 7. genes Risk 4: Risk4 is 2 genetic, and genetic score 4 is 3 genetic (i.e. the same as the original score). 8. scores 1 and 2 are 0 and 3, respectively. 9. gen Risk 5: Gen Risk 6 is 5 genetic and gen score 6 = 0 genetic scores. 10. scoring 1, 2, 3 and 4 are 1-5, 1-, 2-3, 4-6, 5-7, 7-8, 9-10, 11-12, 13-14, 15-16, 17-18, 19-20, 21-22, 23-23, 24-25, 26-27, 28-29, 30-31, 32-33, 34-35, 36-37, 38-39, 40-41, 42-43, 44-44, 45-46, 47-48, 49-50, 51-52, 53-54, 55-56, 57-58, 59-60, 61-62, 63-64, 65-66, 67-67, 68-68, 69-69, 70-71, 72-73, 74-75, 76-77, 78-79, 80-81, 82-82, 83-84, 85-86, 87-88, 89-90, 91-92, 93-94, 95-96, 97-98, 99-100, 101-102, 103-104, 105-106, 107-108, 109-110, 111-112, 113-114, 115-116, 117-117, 118-119, 120-121, 122-123, 124-125, 126-127, 128-129, 130-131, 132-133, 134-135, 136-137, 138-139, 140-141, 142-143, 144-145, 146-147, 148-149, 150-151, 152-153, 154-155, 156-157, 158-159, 160-161, 162-163, 164-165, 166-167, 168-169, 170-171, 172-173, 174-175, 176-177, 178-179, 180-181, 182-183, 184-185, 186-186, 187-188, 189-189, 190-191, 192-193, 194-194, 195-196, 197-197, 198-199, 200-201, 202-203, 204-204, 205-206, 207-208, 209-210, 211-212, 213-214, 215-216, 217-219, 220-221, 222-222, 223-224, 225-226, 227-228, 229-230, 231-232, 233-234, 235-237, 238-239, 240-241, 243-244, 245-246, 247-248, 249-250, 251-252, 253-253, 254-255, 256-257, 258-259, 260-261, 262-263, 264-265, 266-267, 268-269, 270-271, 272-273, 274-275, 276-277, 278-279, 280-281, 282-283, 285-286, 287-288, 289-290, 291-292, 293-294, 295-296, 297-300, 301-302, 303-303, 304-305, 306-307, 308-309, 310-311, 312-313, 314-315, 316-316, 317-318, 319-320, 321-322, 323-324, 325-326, 327-328, 329-330, 331-333, 334-335, 336-337, 338-339, 341-343, 344-345, 346-347, 348-349, 350-351, 353-354, 355-356, 357-358, 359-360, 361-363, 364-364, 365-366, 367-368, 369-370, 371-372, 373-374, 375-376, 377-378, 379-380, 383-384, 385-386, 387-388, 389-390, 391-393, 400-403, 405-406, 407-408, 408-409, 410-411, 412-413, 415-416, 417-417, 418-419, 420-421, 423-424, 425-426, 427-428, 429-430, 430-431, 433-434, 435-436, 436-437, 440-441, 443-444, 445-446, 457-448, 450-451, 455-456, 458-457, 460-461, 465-466, 470-471, 481-, 482-, 490-, 493-, 506-, 510-, 511-, 512-, and 513-, respectively, are the numbers of individuals that have a high risk and a low risk (eigenvalues greater that 1).\n",
      "In the case of any gene, its Risk Scores may vary from 0 to 1 depending upon its genetic background. These scores may range from 1 to 5, with the higher scores indicating a more severe genetic condition, to 0, indicating no genetic disease, 0 or 1 indicating an increase in disease risk or a decrease in health risk due to a change in genetic makeup. Scores for genes with known risk are also calculated. As a result, scores from genes that fall within a range of 0-1 are used. Score values for other genetic diseases are calculated from the Genetic Variation Score Calculator (GVSC) and are listed in Table 1 below. GVSC is available at http:/genes.gvsc.net/index.htm.\n"
     ]
    }
   ],
   "source": [
    "args2 = GENSettings(\n",
    "    no_repeat_ngram_size=2,  # Prevent repetition of n-grams\n",
    "    temperature=0.7,  # Controls randomness (higher values make it more random)\n",
    "    top_k=50,  # Controls the number of next words to consider (higher values make it more deterministic)\n",
    "    top_p=0.95,  # Controls the diversity of next-word distribution (higher values make it more diverse)\n",
    "    max_length=4000,  # Maximum length of the generated text\n",
    "    early_stopping=True  # Stop generation when an end sequence is encountered)\n",
    ")\n",
    "example_res2 = happy_gen.generate_text(example_prompt, args=args2)\n",
    "print(example_res2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1953132-892e-417e-8180-b0ced06cca73",
   "metadata": {},
   "source": [
    "### Fewshot Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae99d1c-efe6-44b5-b876-e38484c63280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from happytransformer import HappyGeneration, GENTrainArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5c12391-1239-44b9-a2b9-9b0be3749b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022 11 29 11 11 53 29 47 REDACTED REDACTED MyRisk Genetic Result Name REDACTED REDACTED DOBESep 13 1983 Accession 04370339 BLD Report Date Sep 09 2022 BREAST CANCER RISKSCORE REDACTED The breast cancer RiskScore provides 5 year and remaining lifetime breast cancer risks based on an analysis of genetic markers combined with patient clinical and family history data The Technical Specifications summary http myriad com technical specifications describes the RiskScore eligibility criteria analysis method performance and interpretive criteria of this test Data from 149 biomarkers are analyzed during next generation sequencing NGS The allele status of these markers has been weighted to generate a polygenic odds ratio of 1 0 for this patient which is combined with clinical and family history information to generate the final RiskScore This odds ratio is adjusted for overlap between the risk captured by the biomarkers and the clinical factors and has not been validated for use with other risk models The Clinical and Cancer Family History Information section of this report displays the data used for this analysis and explains important limitations on the accuracy of RiskScore including significant over or under estimates of breast cancer risk that can be caused by errors and or omissions in the reported clinical and family history data Please contact REDACTED Medical Services at 1 800 469 7423 K 3850 to discuss any questions regarding this result estilt Page 4 of 4 REDACTED genetics'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbe4953e-5fcb-4981-8272-f1a6ca9da7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "print(len(useful_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6de707d4-3709-422e-9401-f18c5a101982",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt_template = \"Based on this medical page content. For example, '{}' \\n Generate a similar synthetic patients' medical page content:\"\n",
    "useful_pages_to_train = useful_pages[:10]  # Your list of useful pages\n",
    "\n",
    "# Path to the training data file\n",
    "train_data_path = '/ghdevhome/home/cpan/gpt_neo_train_train_test_results_pages.txt'\n",
    "\n",
    "# Open the training data file for writing\n",
    "with open(train_data_path, \"w\", encoding=\"utf-8\") as train_file:\n",
    "    for page_content in useful_pages:\n",
    "        # Write the target text to the file\n",
    "        train_file.write(f\"{page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e3f55d4-617e-427c-a314-37d13107287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare the train.txt data with all the test results from test results \n",
    "# # use 10 examples\n",
    "# train_data = [f\"{prompt}\\n\" for prompt in useful_pages][:10]  # Add \"\\n\" at the end of each prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9f05c47-766d-4361-a376-75632a9d25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = GENTrainArgs(\n",
    "    num_train_epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "495bb8b8-72a2-4105-bf73-7d619b7a77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e67a50fb-90d3-442d-8a63-6204b1e754dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/29/2023 10:15:22 - INFO - happytransformer.happy_transformer -   Using device: cuda:0\n",
      "Using pad_token, but it is not set yet.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 50257. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "08/29/2023 10:15:22 - INFO - happytransformer.happy_transformer -   Tokenizing training data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f6b43eb9a44a9bbd98bbdb42c3b6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/62 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a71894f7d347fdb037dc530e670730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/62 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d17ab71c3c4cab96ef40fd43480e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5bc7a87be2446fb345b158a1ac1906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/29/2023 10:15:23 - INFO - happytransformer.happy_transformer -   Moving model to cuda:0\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 12.00 MiB (GPU 6; 79.35 GiB total capacity; 1.05 GiB already allocated; 5.19 MiB free; 1.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model1 \u001b[38;5;241m=\u001b[39m HappyGeneration(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT-NEO\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEleutherAI/gpt-neo-125M\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m model1\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m checkpoint_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/ghdevhome/home/cpan/models/gpt_neo_checkpoint2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m happy_gen\u001b[38;5;241m.\u001b[39msave(checkpoint_dir)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/happytransformer/happy_generation.py:92\u001b[0m, in \u001b[0;36mHappyGeneration.train\u001b[0;34m(self, input_filepath, args, eval_filepath)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_filepath: \u001b[38;5;28mstr\u001b[39m,  args: GENTrainArgs \u001b[38;5;241m=\u001b[39mGENTrainArgs(), eval_filepath: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHappyGeneration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_filepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/happytransformer/happy_transformer.py:110\u001b[0m, in \u001b[0;36mHappyTransformer.train\u001b[0;34m(self, input_filepath, args, eval_filepath)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease set TrainArgs.eval_ratio to greater than 0  or supply an eval_path\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    106\u001b[0m train_tok_data, eval_tok_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data_train(input_filepath\u001b[38;5;241m=\u001b[39minput_filepath,\n\u001b[1;32m    107\u001b[0m                                                       eval_filepath\u001b[38;5;241m=\u001b[39meval_filepath,\n\u001b[1;32m    108\u001b[0m                                                       args\u001b[38;5;241m=\u001b[39margs)\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tok_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_tok_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_collator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/happytransformer/happy_transformer.py:272\u001b[0m, in \u001b[0;36mHappyTransformer._run_train\u001b[0;34m(self, train_dataset, eval_dataset, args, data_collator)\u001b[0m\n\u001b[1;32m    263\u001b[0m trainer \u001b[38;5;241m=\u001b[39m train_class(\n\u001b[1;32m    264\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    265\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m    270\u001b[0m )\n\u001b[1;32m    271\u001b[0m trainer\u001b[38;5;241m.\u001b[39madd_callback(FistStep())\n\u001b[0;32m--> 272\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/trainer.py:1837\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1837\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1840\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1843\u001b[0m ):\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1845\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/trainer.py:2682\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2682\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2685\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/trainer.py:2707\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2705\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2706\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2707\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2708\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2709\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:170\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 170\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, kwargs)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:175\u001b[0m, in \u001b[0;36mDataParallel.replicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplicate\u001b[39m(\u001b[38;5;28mself\u001b[39m, module, device_ids):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/parallel/replicate.py:106\u001b[0m, in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m    103\u001b[0m buffer_indices_not_rg \u001b[38;5;241m=\u001b[39m {buf: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, buf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(buffers_not_rg)}\n\u001b[1;32m    105\u001b[0m buffer_copies_rg \u001b[38;5;241m=\u001b[39m _broadcast_coalesced_reshape(buffers_rg, devices, detach\u001b[38;5;241m=\u001b[39mdetach)\n\u001b[0;32m--> 106\u001b[0m buffer_copies_not_rg \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_coalesced_reshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffers_not_rg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(network\u001b[38;5;241m.\u001b[39mmodules())\n\u001b[1;32m    109\u001b[0m module_copies \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m devices]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/parallel/replicate.py:67\u001b[0m, in \u001b[0;36m_broadcast_coalesced_reshape\u001b[0;34m(tensors, devices, detach)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Broadcast\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detach:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_coalesced\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Use the autograd function to broadcast if not detach\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensors) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/parallel/comm.py:58\u001b[0m, in \u001b[0;36mbroadcast_coalesced\u001b[0;34m(tensors, devices, buffer_size)\u001b[0m\n\u001b[1;32m     56\u001b[0m devices \u001b[38;5;241m=\u001b[39m [_get_device_index(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m devices]\n\u001b[1;32m     57\u001b[0m tensors \u001b[38;5;241m=\u001b[39m [_handle_complex(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tensors]\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_broadcast_coalesced\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 6; 79.35 GiB total capacity; 1.05 GiB already allocated; 5.19 MiB free; 1.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model1 = HappyGeneration(\"GPT-NEO\", \"EleutherAI/gpt-neo-125M\")\n",
    "model1.model.to(device)\n",
    "model1.train(train_data_path, args =training_args)\n",
    "\n",
    "checkpoint_dir = \"/ghdevhome/home/cpan/models/gpt_neo_checkpoint2\"\n",
    "happy_gen.save(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d36d2b1d-d28a-468f-b756-fc9b45ce8a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/29/2023 10:15:47 - INFO - happytransformer.happy_transformer -   Using device: cuda:0\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 50257. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    }
   ],
   "source": [
    "trained_model = HappyGeneration(\"GPT-NEO\", \"/ghdevhome/home/cpan/models/gpt_neo_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "951c442c-2809-4534-a5fa-1df2d11797bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84537e4f-aba3-404c-bbc0-b54ab6adc9ca",
   "metadata": {},
   "source": [
    "### Different Test Prompts Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb4c88f1-6e45-443f-b1a2-0443dc7ed69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw test prompt without any context \n",
    "test_prompt1 = 'Generate synthetic patient page content: '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc3f3c6b-7d27-497e-b4ca-1ca7b555edaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A:\n",
      "   <script src=\"https://ajax.googleapis.com/aj�/cloud-native/v3/lib/jquery/1.11.3.min.js\"></script>\n",
      "<script type=\"text/javascript\">\n",
      "$(document).ready(function(){\n",
      "var $ = $('#my-page');\n",
      "if(!$){\n",
      "alert('No page loaded');  //alert(\"No pages loaded\");\n",
      "}\n",
      "});\n",
      "</script></head>\n",
      "\n",
      "  </body> \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_res_trained1 = trained_model.generate_text(test_prompt1, args=args2)\n",
    "print(example_res_trained1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e7d53f28-8438-44dd-b4ad-f6cd50d469cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on this medical page content,for example: 'PATIENT COPY conripentiat eee 53737937 myRisk Genetic Result Name REDACTED REDACTED DOB Aug 16 1969 Accession 03568288 BLD Report Date Fab 24 2020 Please contact REDACTED Medical Services at 1 800 469 7423 K 3850 to discuss any questions regarding this result These test results should only be used in conjunetion with the patient s cb i history and any previous analysis of appropriate family members The pahant s clinical history and test results should not be disclosed to a third party unle related to treatment or payment for treatment without the patient s express writer authorization It is strongly recommended hat these results be comrounmated to the patient in a setting that inciudes appropriate genatic consultation REDACTED lest was developed and its performance characteristics determined by REDACTED Genetic Laboratorigs It has not been cleared or approved by the REDACTED Food and Drug Administration FDA The FDA has determined that clearance ar apnroval for laboratory developed tests is not required 2020 REDACTED Ganatics nc 320 REDACTED REDACTED tah 84108 PH 1 800 469 7423 FX 801 584 3613 The format and contents of this reporl are praprietary and may not be copied cr used without permission except for purposes of diagnosing Counseling and treating he patient identified in the report and members of his or her family REDACTED REDACTED myRisk riskBcore REDACTED COLARIS myVision and their respective logas are either trademarks or ragistered trademarks af REDACTED myRisk Genetic Result Genetics Inc in REDACTED and other jurisdictions REDACTED of 2'. \\n Generate a similar synthetic patients' medical page content:\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_prompts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d2885725-ea21-40f6-9652-f3f185c8f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prompt with more context (but providing the test data) \n",
    "example_test_prompt = all_test_prompts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8cebc28d-dc20-4838-801a-7306d428d100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(all_test_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "80e0c389-875a-4e2e-89da-bbb285c979b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This page contains the following text:  \n",
      "\n",
      "  1.  The patient is a patient of the FDA.\n",
      "  2. The physician is the physician of REDACHANTI.\n",
      "\n",
      "\n",
      "The patient's medical history is provided in this page. This page is intended to be a summary of a physician's clinical experience. It does not include any information about the medical condition of any patient. If the doctor is unable to provide a medical opinion, the information provided by a doctor may be considered confidential. REDATHAN MEDICAL SERVICES, INC. is an authorized physician in California.\n"
     ]
    }
   ],
   "source": [
    "example_res_trained2 = trained_model.generate_text(example_test_prompt, args=args2)\n",
    "print(example_res_trained2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2e67adb5-2c04-477c-974d-3c515205b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prompt by mentioning competitors' test names \n",
    "test_prompt2 = \"For the competitor's test as 'MyRisk'. Generate synthetic patient page content: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8d773024-6c63-4670-bfe4-b266175c3706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A:\n",
      "   <div class=\"row\">\n",
      "<div>\n",
      "</div><!-- /row -->\n",
      "...\n",
      "<?php\n",
      "$row = mysql_fetch_array($query);\n",
      "if (mysql_num_rows($row) > 0) {\n",
      "?>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_res_trained3 = trained_model.generate_text(test_prompt2, args=args2)\n",
    "print(example_res_trained3.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e3a1bd9-63fa-471f-9bd1-5f7d30aaef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepara test prompts \n",
    "new_prompt_template2 = \"Generate a synthetic medical page content similar to the provided example: {}\"\n",
    "all_test_prompts_new = []\n",
    "# try 10 examples\n",
    "for page_content in test_pages:\n",
    "  full_prompt = new_prompt_template2.format(page_content)\n",
    "  all_test_prompts_new.append(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d34ea42f-5950-48c5-bd62-28770a5bcccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generate a synthetic medical page content similar to the provided example: CTCA Rightfax 1 22 2021 1 35 05 PM PAGE 9 040 Fax b5erver JACKSON REDACTED 6 15 2020 SEP20 534 REDACTED REDACTED 46263197 DOB AUG O1 1994 f Test Number 4 Definitions Somatic Afterations Not Detected ND or variant Characteristics may re dees not pr be present that are below the limit of detaction of this tivity The absence of delectable somatic alterations in circuiatir tumor in sampte 2 ONA interpretations Somatic altera types af yenum ions were NOT detected in th DNA isolated from this patient alterations chetented by GuardantséG This versiue of the Quardantsad tes is of gonomic alterations such as complex rearrangements or gene deletions nlood specirn not validated for toes the other types GUARBANT HE jad Guardtant360 Patient Report antine portat TST PRT 001 V2 Bortal quardanthealth com of to set up an aecount Gontaet Client Services 885 858 REDACTED REDACTED JONNA Page 4 of 5'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_prompts_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b85f7e61-5373-4d27-a829-49563a7b642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_res_trained4 = trained_model.generate_text(all_test_prompts_new[0], args=args2)\n",
    "# print(example_res_trained4.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd7d0dc-5e27-4693-9862-a81213927570",
   "metadata": {},
   "source": [
    "### Test Resulst Generation & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18f047b5-48a6-4f12-bf54-18908a85624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args2 = GENSettings(\n",
    "    no_repeat_ngram_size=2,  # Prevent repetition of n-grams\n",
    "    temperature=0.7,  # Controls randomness (higher values make it more random)\n",
    "    top_k=50,  # Controls the number of next words to consider (higher values make it more deterministic)\n",
    "    top_p=0.95,  # Controls the diversity of next-word distribution (higher values make it more diverse)\n",
    "    max_length=2000,  # Maximum length of the generated text\n",
    "    early_stopping=True, # Stop generation when an end sequence is encountered\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3abd5f0b-6a2e-45d6-8904-419f77553696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "762a4e09-734f-49a0-b905-230b1fe385ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')  # For GPU\n",
    "torch.set_default_tensor_type('torch.FloatTensor')  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b0b4424-7d4e-424b-ac2a-be714369db9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generate a synthetic medical page content similar to the provided example: CTCA Rightfax 1 22 2021 1 35 05 PM PAGE 9 040 Fax b5erver JACKSON REDACTED 6 15 2020 SEP20 534 REDACTED REDACTED 46263197 DOB AUG O1 1994 f Test Number 4 Definitions Somatic Afterations Not Detected ND or variant Characteristics may re dees not pr be present that are below the limit of detaction of this tivity The absence of delectable somatic alterations in circuiatir tumor in sampte 2 ONA interpretations Somatic altera types af yenum ions were NOT detected in th DNA isolated from this patient alterations chetented by GuardantséG This versiue of the Quardantsad tes is of gonomic alterations such as complex rearrangements or gene deletions nlood specirn not validated for toes the other types GUARBANT HE jad Guardtant360 Patient Report antine portat TST PRT 001 V2 Bortal quardanthealth com of to set up an aecount Gontaet Client Services 885 858 REDACTED REDACTED JONNA Page 4 of 5'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_prompts_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3488e99-35f0-4a0d-a4e4-2084752b6b32",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m generated_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_prompt \u001b[38;5;129;01min\u001b[39;00m all_test_prompts_new[:\u001b[38;5;241m5\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m     gen_res \u001b[38;5;241m=\u001b[39m \u001b[43mtrained_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     generated_text \u001b[38;5;241m=\u001b[39m gen_res\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m     generated_texts\u001b[38;5;241m.\u001b[39mappend(generated_text)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/happytransformer/happy_generation.py:72\u001b[0m, in \u001b[0;36mHappyGeneration.generate_text\u001b[0;34m(self, text, args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     bad_words_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjusted_min_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_full_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjusted_max_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbad_words_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbad_words_ids\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GenerationResult(text\u001b[38;5;241m=\u001b[39moutput[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:204\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/base.py:1129\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1122\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1123\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1126\u001b[0m         )\n\u001b[1;32m   1127\u001b[0m     )\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/base.py:1136\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1135\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1136\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/base.py:1034\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1032\u001b[0m inference_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_inference_context()\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m-> 1034\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_tensor_on_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[1;32m   1036\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/base.py:939\u001b[0m, in \u001b[0;36mPipeline._ensure_tensor_on_device\u001b[0;34m(self, inputs, device)\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {name: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(tensor, device) \u001b[38;5;28;01mfor\u001b[39;00m name, tensor \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, UserDict):\n\u001b[0;32m--> 939\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m UserDict(\u001b[43m{\u001b[49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_tensor_on_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(item, device) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m inputs]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/base.py:939\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {name: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(tensor, device) \u001b[38;5;28;01mfor\u001b[39;00m name, tensor \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, UserDict):\n\u001b[0;32m--> 939\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m UserDict({name: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_tensor_on_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name, tensor \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(item, device) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m inputs]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/pipelines/base.py:947\u001b[0m, in \u001b[0;36mPipeline._ensure_tensor_on_device\u001b[0;34m(self, inputs, device)\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m {torch\u001b[38;5;241m.\u001b[39mfloat16, torch\u001b[38;5;241m.\u001b[39mbfloat16}:\n\u001b[1;32m    946\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m--> 947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "generated_texts = []\n",
    "for test_prompt in all_test_prompts_new[:5]:\n",
    "    gen_res = trained_model.generate_text(test_prompt, args=args2)\n",
    "    generated_text = gen_res.text.to(device)\n",
    "    generated_texts.append(generated_text)\n",
    "\n",
    "    # Print device information for tensors\n",
    "    print(f\"Generated text device: {gen_res.text.device if hasattr(gen_res.text, 'device') else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08e42d2f-609a-42ba-9668-5a26585dbdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_texts = test_pages.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "975eb18d-7487-4acc-bca7-315094bbcd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CTCA Rightfax 1 22 2021 1 35 05 PM PAGE 9 040 Fax b5erver JACKSON REDACTED 6 15 2020 SEP20 534 REDACTED REDACTED 46263197 DOB AUG O1 1994 f Test Number 4 Definitions Somatic Afterations Not Detected ND or variant Characteristics may re dees not pr be present that are below the limit of detaction of this tivity The absence of delectable somatic alterations in circuiatir tumor in sampte 2 ONA interpretations Somatic altera types af yenum ions were NOT detected in th DNA isolated from this patient alterations chetented by GuardantséG This versiue of the Quardantsad tes is of gonomic alterations such as complex rearrangements or gene deletions nlood specirn not validated for toes the other types GUARBANT HE jad Guardtant360 Patient Report antine portat TST PRT 001 V2 Bortal quardanthealth com of to set up an aecount Gontaet Client Services 885 858 REDACTED REDACTED JONNA Page 4 of 5'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c15dccae-58e8-4c2b-93e1-0fbcc9761f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a9974d34-e233-4bf7-995b-5d8507789513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16941af7-31c4-4cf1-80fc-5349521a1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_scores = []\n",
    "rouge_scores = []\n",
    "\n",
    "# Loop through generated and reference texts\n",
    "for generated_text, reference_text in zip(generated_texts, reference_texts):\n",
    "    # Compute BLEU score\n",
    "    bleu_score = sentence_bleu([reference_text.split()], generated_text.split())\n",
    "    bleu_scores.append(bleu_score)\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    rouge = Rouge()\n",
    "    rouge_scores.append(rouge.get_scores(generated_text, reference_text)[0]['rouge-l']['f'])\n",
    "\n",
    "# Calculate average BLEU and ROUGE scores\n",
    "average_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "average_rouge = sum(rouge_scores) / len(rouge_scores)\n",
    "\n",
    "print(f\"Average BLEU Score: {average_bleu:.4f}\")\n",
    "print(f\"Average ROUGE Score: {average_rouge:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
